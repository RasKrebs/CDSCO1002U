{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 12:45:01.481162: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import os\n",
    "from modules.utils import SentimentDataset\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, classification_report\n",
    "from itertools import chain\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining relevant paths\n",
    "\n",
    "CURDIR = os.getcwd()\n",
    "MODELS = os.path.join(CURDIR, 'models')\n",
    "BERT_PATH = os.path.join(MODELS, 'BERT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model from pretrained\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_PATH)\n",
    "model = BertForSequenceClassification.from_pretrained(BERT_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sentiment140 (/Users/krebs/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/f81c014152931b776735658d8ae493b181927de002e706c4d5244ecb26376997)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735209e7ca3149ebb4d48eb60d45f941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = load_dataset('sentiment140')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sentiment140 (/Users/krebs/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/f81c014152931b776735658d8ae493b181927de002e706c4d5244ecb26376997)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0e1c513433429ba149b5a41b10edc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing\n",
      "Processing test input\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset('sentiment140')\n",
    "\n",
    "# Create subset based on new data\n",
    "test_set = df['train'].to_pandas().groupby('sentiment').apply(lambda x: x[-1000:]).reset_index(drop=True).replace(4, 1).sample(frac=1)\n",
    "\n",
    "sentences = SentimentDataset(test_set.text.to_list(), subset='test').process_data()\n",
    "labels = test_set.sentiment.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  home school let early\n",
      "Token IDs: tensor([[ 101, 2188, 2082, 2292, 2220,  102,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0]])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# Same processes as for training\n",
    "for sent in sentences:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      \n",
    "                        add_special_tokens = True, \n",
    "                        max_length = 70,           \n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True, \n",
    "                        return_tensors = 'pt')     \n",
    "\n",
    "    # Add the encoded sentence to the list\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding)\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])\n",
    "\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the batch size - same as training\n",
    "batch_size = 32  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = tuple(t for t in batch)\n",
    "  \n",
    "  # Similarly to validation during training, computing gradient is not necessary\n",
    "  with torch.no_grad():\n",
    "      \n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  logits = logits.detach().numpy()\n",
    "  label_ids = b_labels.numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_labels = list(chain.from_iterable(predictions))\n",
    "test_true_labels = list(chain.from_iterable(true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_labels = [np.argmax(pred) for pred in test_pred_labels]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.799"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_true_labels, test_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80      1000\n",
      "           1       0.82      0.77      0.79      1000\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.80      0.80      0.80      2000\n",
      "weighted avg       0.80      0.80      0.80      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_true_labels, test_pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fdac1fb2e20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(test_true_labels, test_pred_labels)).plot()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Indices of wrong predictions\n",
    "wrong_predictions = [i for i, (a,b) in enumerate(zip(test_pred_labels, test_true_labels)) if a != b]\n",
    "\n",
    "# Random list of 5 index positions\n",
    "indexes = [wrong_predictions[random.randint(0, len(wrong_predictions)-1)] for _ in range(5)]\n",
    "\n",
    "# Original tweet\n",
    "original = test_set.text.to_list()\n",
    "\n",
    "# Processed tweet \n",
    "processed = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tweet                                                                                                             Processed Tweet                                                          True Label    Predicted Label\n",
      "-------------------------------------------------------------------------------------------------------------------------  ---------------------------------------------------------------------  ------------  -----------------\n",
      "@gagova75 @QueenM81  after this break, it's time for me to go back to work. BBS &lt;3 Have fun                             break time go back work bb lt fun                                                 1                  0\n",
      "@Ms_Hip_Hop there will be no sleepin on twitter young lady. LOL im at work these NJ cops are gansta they stoppin everybdy  sleepin twitter young lady lol im work nj cop gansta stoppin everybdy             0                  1\n",
      "@ISmackYourAss I know now I can't read ur storys                                                                           know read ur story                                                                0                  1\n",
      "@christinajade Farrah was a beauty  @antipov Hello! Nice to 'meet' ya!  @Winkfromblueyes you're too kind. TY!              farrah beauty hello nice meet ya kind ty                                          0                  1\n",
      "@teckie She just did  As reported on CNN; she was my favorite Charlie's Angel                                              reported cnn favorite charlie angel                                               0                  1\n"
     ]
    }
   ],
   "source": [
    "table = [[original[i], processed[i], test_true_labels[i], test_pred_labels[i]]\n",
    "         for i in indexes]\n",
    "print(tabulate(table, headers=[\"Original Tweet\", \"Processed Tweet\", \"True Label\", \"Predicted Label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
